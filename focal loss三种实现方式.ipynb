{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def binary_focal_loss(gamma=2, alpha=0.25):\n",
    "    \"\"\"\n",
    "    Binary form of focal loss.\n",
    "    适用于二分类问题的focal loss\n",
    "    \n",
    "    focal_loss(p_t) = -alpha_t * (1 - p_t)**gamma * log(p_t)\n",
    "        where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n",
    "    References:\n",
    "        https://arxiv.org/pdf/1708.02002.pdf\n",
    "    Usage:\n",
    "     model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "    \"\"\"\n",
    "    alpha = tf.constant(alpha, dtype=tf.float32)\n",
    "    gamma = tf.constant(gamma, dtype=tf.float32)\n",
    "\n",
    "    def binary_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        y_true shape need be (None,1)\n",
    "        y_pred need be compute after sigmoid\n",
    "        \"\"\"\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        alpha_t = y_true*alpha + (K.ones_like(y_true)-y_true)*(1-alpha)\n",
    "    \n",
    "        p_t = y_true*y_pred + (K.ones_like(y_true)-y_true)*(K.ones_like(y_true)-y_pred) + K.epsilon()\n",
    "        focal_loss = - alpha_t * K.pow((K.ones_like(y_true)-p_t),gamma) * K.log(p_t)\n",
    "        return K.mean(focal_loss)\n",
    "    return binary_focal_loss_fixed\n",
    "\n",
    "\n",
    "\n",
    "def multi_category_focal_loss1(alpha, gamma=2.0):\n",
    "    \"\"\"\n",
    "    focal loss for multi category of multi label problem\n",
    "    适用于多分类或多标签问题的focal loss\n",
    "    alpha用于指定不同类别/标签的权重，数组大小需要与类别个数一致\n",
    "    当你的数据集不同类别/标签之间存在偏斜，可以尝试适用本函数作为loss\n",
    "    Usage:\n",
    "     model.compile(loss=[multi_category_focal_loss1(alpha=[1,2,3,2], gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "    \"\"\"\n",
    "    epsilon = 1.e-7\n",
    "    alpha = tf.constant(alpha, dtype=tf.float32)\n",
    "    #alpha = tf.constant([[1],[1],[1],[1],[1]], dtype=tf.float32)\n",
    "    #alpha = tf.constant_initializer(alpha)\n",
    "    gamma = float(gamma)\n",
    "    def multi_category_focal_loss1_fixed(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "        y_t = tf.multiply(y_true, y_pred) + tf.multiply(1-y_true, 1-y_pred)\n",
    "        ce = -tf.log(y_t)\n",
    "        weight = tf.pow(tf.subtract(1., y_t), gamma)\n",
    "        fl = tf.reduce_sum(tf.multiply(tf.multiply(weight, ce), alpha), reduction_indices=1)\n",
    "#         fl = tf.matmul(tf.multiply(weight, ce), alpha)\n",
    "        loss = tf.reduce_mean(fl)\n",
    "        return loss\n",
    "    return multi_category_focal_loss1_fixed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def multi_category_focal_loss2(gamma=2., alpha=.25):\n",
    "    \"\"\"\n",
    "    focal loss for multi category of multi label problem\n",
    "    适用于多分类或多标签问题的focal loss\n",
    "    alpha控制真值y_true为1/0时的权重\n",
    "        1的权重为alpha, 0的权重为1-alpha\n",
    "    当你的模型欠拟合，学习存在困难时，可以尝试适用本函数作为loss\n",
    "    当模型过于激进(无论何时总是倾向于预测出1),尝试将alpha调小\n",
    "    当模型过于惰性(无论何时总是倾向于预测出0,或是某一个固定的常数,说明没有学到有效特征)\n",
    "        尝试将alpha调大,鼓励模型进行预测出1。\n",
    "    Usage:\n",
    "     model.compile(loss=[multi_category_focal_loss2(alpha=0.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "    \"\"\"\n",
    "    epsilon = 1.e-7\n",
    "    gamma = float(gamma)\n",
    "    alpha = tf.constant(alpha, dtype=tf.float32)\n",
    "\n",
    "    def multi_category_focal_loss2_fixed(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "    \n",
    "        alpha_t = y_true*alpha + (tf.ones_like(y_true)-y_true)*(1-alpha)\n",
    "        y_t = tf.multiply(y_true, y_pred) + tf.multiply(1-y_true, 1-y_pred)\n",
    "        ce = -tf.log(y_t)\n",
    "        weight = tf.pow(tf.subtract(1., y_t), gamma)\n",
    "        fl = tf.multiply(tf.multiply(weight, ce), alpha_t)\n",
    "        loss = tf.reduce_mean(fl)\n",
    "        return loss\n",
    "    return multi_category_focal_loss2_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(y_true, y_pred, gamma=2., alpha=.25):\n",
    "    pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "    pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "    return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
